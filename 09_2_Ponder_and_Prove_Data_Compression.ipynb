{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_2_Ponder_and_Prove_Data_Compression.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spencerleewilliams/cse380-notebooks/blob/master/09_2_Ponder_and_Prove_Data_Compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rG4k7VvQ2WT"
      },
      "source": [
        "# Ponder and Prove Data Compression\n",
        "#### Due: Saturday, 6 March 2021, 11:59 pm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0WxE3IAQ2WU"
      },
      "source": [
        "# TODO Explore Huffman Trees and Huffman Codes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2vby9erSjOv"
      },
      "source": [
        "Your task is examine how to compress a *special piece of information* as compactly as possible, and **calculate various compression ratios**.\n",
        "\n",
        "Recall that the **compression ratio** of a variable-length encoding like Huffman encoding is the percentage $100(f - v)/f$, where $f$ is the number of bits per symbol of the smallest **fixed**-length encoding, and $v$ is the average number of bits per symbol with the variable-length encoding.\n",
        "\n",
        "For example, if there were 9 different symbols in a message, $f=4$ is the number of bits of the smallest fixed-length encoding, because $2^3 = 8$ (not enough for $9$) and $2^4 = 16$ (enough and to spare). If the variable-length encoding of the message had $v=3.12$, the compression ratio would be $100(4 - 3.12)/4 \\approx 22\\%$.\n",
        "\n",
        "Note that calculating the average number of bits per symbol is not strictly necessary. That's because an alternate and equivalent way is to calculate $100(ft - vt)/ft$, where $ft$ is the **total** number of bits encoded with the fixed encoding, and $vt$ is the **total** number of bits encoded with the variable-length encoding.\n",
        "\n",
        "The *special piece of information* to be compressed is a list of the first ten million primes. This is a list that starts\n",
        "\n",
        "|    |\n",
        "|----|\n",
        "|  2 |\n",
        "|  3 |\n",
        "|  5 |\n",
        "|  7 |\n",
        "| 11 |\n",
        "| 13 |\n",
        "| 17 |\n",
        "| 19 |\n",
        "| 23 |\n",
        "| 29 |\n",
        "\n",
        "  and ends\n",
        "\n",
        "|           |\n",
        "|-----------|\n",
        "| 179424551 |\n",
        "| 179424571 |\n",
        "| 179424577 |\n",
        "| 179424601 |\n",
        "| 179424611 |\n",
        "| 179424617 |\n",
        "| 179424629 |\n",
        "| 179424667 |\n",
        "| 179424671 |\n",
        "| 179424673 |\n",
        "\n",
        "As ASCII text stored in a file with one prime per line, the size of this data file is slightly over 89 megabytes. The goal is to compress this down to just over 5 megabytes (5589056 bytes, to be exact). That's a 94% compression ratio!\n",
        "\n",
        "Standard compression tools can only get about a 73% compression ratio for this ASCII data. A more clever approach is needed. Instead of compressing the list of prime numbers, compress a list of the *gaps* between them!\n",
        "\n",
        "It doesn't save much, just the unique (occurring only once) gap size of 1 between 2 and 3, but in the spirit of de Polignac's conjecture that every *even* number appears infinitely often as a gap between consecutive primes, just consider the even-sized gaps. The result will be a list that starts with 2 (the difference between 5 and 3), 2 (the difference between 7 and 5), 4 (the difference between 11 and 7), 2 (the difference between 13 and 11), 4 (the difference between 17 and 13), 2 (the difference between 19 and 17), 4 (the difference between 23 and 19), and 6 (the difference between 29 and 23).\n",
        "\n",
        "Generating this data is the first task. The algorithm for doing so is very straightforward:\n",
        "\n",
        "1. Find the gaps between consecutive odd primes.\n",
        "2. Store these gaps as a list of even numbers.\n",
        "\n",
        "Tabulating the results, the first ten gaps and the last ten gaps are as follows, where the numbers after the equals signs are the gaps to list:\n",
        "\n",
        "|                 |\n",
        "|-----------------|\n",
        "|  5  -   3  =  2 |\n",
        "|  7  -   5  =  2 |\n",
        "| 11  -   7  =  4 |\n",
        "| 13  -  11  =  2 |\n",
        "| 17  -  13  =  4 |\n",
        "| 19  -  17  =  2 |\n",
        "| 23  -  19  =  4 |\n",
        "| 29  -  23  =  6 |\n",
        "| 31  -  29  =  2 |\n",
        "| 37  -  31  =  6 |\n",
        "\n",
        "|                                |\n",
        "|--------------------------------|\n",
        "| 179424551  -  179424533  =  18 |\n",
        "| 179424571  -  179424551  =  20 |\n",
        "| 179424577  -  179424571  =   6 |\n",
        "| 179424601  -  179424577  =  24 |\n",
        "| 179424611  -  179424601  =  10 |\n",
        "| 179424617  -  179424611  =   6 |\n",
        "| 179424629  -  179424617  =  12 |\n",
        "| 179424667  -  179424629  =  38 |\n",
        "| 179424671  -  179424667  =   4 |\n",
        "| 179424673  -  179424671  =   2 |\n",
        "\n",
        "As a correctness check, see if your generated list of gaps has length 9999998.\n",
        "\n",
        "The next step is to count how many times each gap size occurs, so that for the Huffman encoding scheme, the larger the frequency of occurrence, the smaller the number of bits encoding that gap size.\n",
        "\n",
        "As a correctness check, here are the first ten and the last ten gap counts:\n",
        "\n",
        "|  Gap | Count   |\n",
        "|------|---------|\n",
        "|    2 |  738597 |\n",
        "|    4 |  738717 |\n",
        "|    6 | 1297540 |\n",
        "|    8 |  566151 |\n",
        "|   10 |  729808 |\n",
        "|   12 |  920661 |\n",
        "|   14 |  503524 |\n",
        "|   16 |  371677 |\n",
        "|   18 |  667734 |\n",
        "|   20 |  354267 |\n",
        "|      |         |\n",
        "|  190 |       1 |\n",
        "|  192 |       3 |\n",
        "|  194 |       1 |\n",
        "|  196 |       1 |\n",
        "|  198 |       6 |\n",
        "|  202 |       2 |\n",
        "|  204 |       3 |\n",
        "|  210 |       4 |\n",
        "|  220 |       1 |\n",
        "|  222 |       1 |\n",
        "\n",
        "Note two things from these partial gap counts:\n",
        "\n",
        "1. Small even numbers (< 100) are well represented, larger ones (< 1000) less so.\n",
        "2. Ten million primes aren't enough to have *every* even number represented; for example, 200, 206, 208, 212, 214, 216, and 218 do not appear even once.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EnqSTavQIdb",
        "outputId": "4bcf2e65-f2b8-436c-9b9f-d5399ed6b189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Code from 9_5\n",
        "!pip install pyprimesieve\n",
        "import pyprimesieve\n",
        "tmp = pyprimesieve.primes_nth(10000000)\n",
        "primes = pyprimesieve.primes(tmp+1)\n",
        "# List of gaps from 1, 10000000\n",
        "gaps = [*map(lambda i:primes[i]-primes[i-1],range(1,10000000))]\n",
        "# pl = prime\n",
        "pl=[2]\n",
        "[pl.append(pl[-1] + g) for g in gaps]\n",
        "print(pl==primes)\n",
        "# Print the total size of gaps\n",
        "print(len(gaps))\n",
        "uniqueGaps = 0\n",
        "# Loop through and print the number of occurances for each gap from 2 to 222\n",
        "for i in range(2, 223):\n",
        "  count = 0\n",
        "  \n",
        "  for gap in gaps:\n",
        "    if (gap == i):\n",
        "      count += 1\n",
        "  if (count > 0):\n",
        "    print(i, count)\n",
        "    uniqueGaps += 1\n",
        "\n",
        "print(uniqueGaps)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyprimesieve in /usr/local/lib/python3.7/dist-packages (0.1.6)\n",
            "True\n",
            "9999999\n",
            "2 738597\n",
            "4 738717\n",
            "6 1297540\n",
            "8 566151\n",
            "10 729808\n",
            "12 920661\n",
            "14 503524\n",
            "16 371677\n",
            "18 667734\n",
            "20 354267\n",
            "22 307230\n",
            "24 453215\n",
            "26 211203\n",
            "28 229177\n",
            "30 398713\n",
            "32 123123\n",
            "34 129043\n",
            "36 206722\n",
            "38 94682\n",
            "40 111546\n",
            "42 159956\n",
            "44 64866\n",
            "46 54931\n",
            "48 93693\n",
            "50 52183\n",
            "52 38800\n",
            "54 64157\n",
            "56 32224\n",
            "58 27985\n",
            "60 55305\n",
            "62 16763\n",
            "64 17374\n",
            "66 30960\n",
            "68 12368\n",
            "70 17475\n",
            "72 17255\n",
            "74 8540\n",
            "76 7253\n",
            "78 13758\n",
            "80 6760\n",
            "82 4791\n",
            "84 9818\n",
            "86 3411\n",
            "88 3454\n",
            "90 7056\n",
            "92 2259\n",
            "94 2058\n",
            "96 3544\n",
            "98 1831\n",
            "100 1923\n",
            "102 2374\n",
            "104 1168\n",
            "106 933\n",
            "108 1634\n",
            "110 941\n",
            "112 711\n",
            "114 1125\n",
            "116 439\n",
            "118 433\n",
            "120 948\n",
            "122 287\n",
            "124 318\n",
            "126 533\n",
            "128 183\n",
            "130 211\n",
            "132 301\n",
            "134 128\n",
            "136 100\n",
            "138 210\n",
            "140 140\n",
            "142 90\n",
            "144 123\n",
            "146 46\n",
            "148 67\n",
            "150 94\n",
            "152 52\n",
            "154 43\n",
            "156 57\n",
            "158 19\n",
            "160 27\n",
            "162 27\n",
            "164 20\n",
            "166 9\n",
            "168 25\n",
            "170 18\n",
            "172 4\n",
            "174 10\n",
            "176 11\n",
            "178 12\n",
            "180 10\n",
            "182 5\n",
            "184 4\n",
            "186 3\n",
            "188 1\n",
            "190 1\n",
            "192 3\n",
            "194 1\n",
            "196 1\n",
            "198 6\n",
            "202 2\n",
            "204 3\n",
            "210 4\n",
            "220 1\n",
            "222 1\n",
            "104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CUIw8_k03JJ"
      },
      "source": [
        "# TODO Determine Exact Size of Data to be Compressed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB4sXf0X09Gv"
      },
      "source": [
        "Without actually doing it, imagine creating an ASCII file containing the first ten million primes, represented in decimal, one prime per line. Calculate the size of this file, so you can show an exceptional compression ratio from it (see below).\n",
        "\n",
        "Using a binary encoding instead of ASCII, each prime requires 32 bits (4 bytes), so the size of a binary file is easily determined.\n",
        "\n",
        "Using a fixed-width encoding of the gap counts, however, requires knowing how many different gap sizes there are, after which the calculation is straightforward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HZChUyC09tJ"
      },
      "source": [
        "# TODO Use Functional Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7vG1XqY1CaV"
      },
      "source": [
        "You are encouraged to use the [anytree](https://pypi.org/project/anytree) Python library, which has a nice exporter by way of which you can graphically view trees. (You may recall using this in DM1, and thus know that **anytree** depends on [graphviz](https://graphviz.org), which you also used.)\n",
        "\n",
        "This library uses the object-oriented features of Python to create and visualize trees. You are encouraged to use the functional features of Python as much as possible, achieving your results not by using some existing third-party libraries for building Huffman Trees and Codes, but writing your own code as cleanly and elegantly as you can."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azLHvKWAQJrp",
        "outputId": "ca662759-37a4-4ead-979a-c4347198d7ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Functions to determine number of digits, considering length and lines.\n",
        "# See 9_5\n",
        "from math import log10, floor\n",
        "def get_num_digits(n):\n",
        "  return len(str(n))\n",
        "\n",
        "def get_num_digits_no_str(n):\n",
        "  return floor(log10(n)) + 1\n",
        "\n",
        "def get_line_size(n):\n",
        "  return get_num_digits_no_str(n) + 1\n",
        "\n",
        "total_size_in_digits = sum(map(lambda p: get_num_digits_no_str(p), primes))\n",
        "# Exact Size of Data for ASCII\n",
        "total_size_in_bits = total_size_in_digits * 8\n",
        "print((total_size_in_digits + 10 ** 7) / 2 ** 20)\n",
        "# Exact Size of Data for binary\n",
        "# Equals the number of primes multiplied by 4 bytes or 32 bits\n",
        "total_size_in_bits = total_size_in_digits * 32\n",
        "print((total_size_in_digits + 10 ** 7) / 2 ** 20)\n",
        "# Exact Size of Data for fixed\n",
        "# Gaps\n",
        "# Number of different gap sizes\n",
        "ceil(log2(uniqueGaps))\n",
        "total_size_in_bits = total_size_in_digits * 104\n",
        "print((total_size_in_digits + 10 ** 7) / 2 ** 20)\n",
        "# Total"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "89.15371894836426\n",
            "89.15371894836426\n",
            "89.15371894836426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUB4mD8u1DCa"
      },
      "source": [
        "# TODO Achieve Target Compression Ratios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vw71EqJ18eE"
      },
      "source": [
        "\n",
        "Your solution should correctly compute the following three compression ratios:\n",
        "\n",
        "| Ratio       | Value              |\n",
        "|-------------|--------------------|\n",
        "| From fixed  | 36.125168653605158 |\n",
        "| From binary |              86.03 |\n",
        "| From ASCII  |              94.02 | \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmvovNXdQL78",
        "outputId": "da421843-5716-4a50-f1ef-0253533f7bd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from math import ceil, log2\n",
        "# Take the The compression ratio of an encoding is the percentage (f − v) / f·100, \n",
        "# where f is the number of bits per symbol of the smallest fixedlength encoding, and v is the average \n",
        "# number of bits per prime with the variable-length (e.g. Huffman) encoding.\n",
        "# f equals number of bits \n",
        "# fixed: 7\n",
        "# binary: 32\n",
        "# ASCII: 8 or 64?\n",
        "# v = 4.71238194 average number of bits per prime\n",
        "# Fixed Compression ratio w/ 104 different gap sizes\n",
        "print(((7 - 4.71238194) / 7) * 100)\n",
        "# Binary Compression ratio\n",
        "print(((32 - 4.471238194) / 32) * 100)\n",
        "# ASCII Compression ratio\n",
        "print(((64 - 4.71238194) / 64) * 100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32.680257999999995\n",
            "86.02738064374999\n",
            "92.63690321875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81dbKwHenxnT"
      },
      "source": [
        "# TODO My Report on What I Did and What I Learned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8BeiIern33B"
      },
      "source": [
        "## Fun\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElukRLoezyxd"
      },
      "source": [
        "Normally I imagine trees spreading outward, expanding rather than compressing. Huffman tree encodings, compressions, and decompressions are unique concepts to the idea of whenever I think of a tree. It was fun to continue expounding my knowledge by compressing Huffman trees. I see it as a valuable form of computation as it allows us to send large files of data in this age quickly via compression while maintaining the key components of the original file. Comparing the values from fixed, binary and ASCII was most interesting to see how the representation of data affects the ability to compress data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzOkZ3son-u9"
      },
      "source": [
        "## New"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-nYIdEUz4x5"
      },
      "source": [
        "Comparing the values from fixed, binary and ASCII was most interesting to see how the representation of data affects the ability to compress data. In DM1, learning about Huffman tree data compression was an interesting concept that we as a class didn't explore too deeply into its applications. I had already known about the general concepts and purposes of data compression with Huffman trees, but seeing how the form of data representation affects compression ratios was an important consideration to learn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJHvoj6GokaZ"
      },
      "source": [
        "## Meaningful\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOxh3XFTz-6N"
      },
      "source": [
        "Related to the two previous prompts, I would like to further research/test forms of data and how they compress. The activity here is with the primes, but what are the similarities and differences to compression when using data beyond integers and strings. In other programming languages, like C++, doubles, etc. include larger allocations of integers, but what about video or images. How does the integrity in data compression differ when the stored value isn't a read message?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RBE03fhpNUG"
      },
      "source": [
        "## Connections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-sXEeq60C3W"
      },
      "source": [
        "One connection that I made to this activity was when I took linear algebra. A section we learned in this course also talked about data compression with images. However, the focus was more on different states or file sizes from a larger state to a smaller state. Similar to earlier topics of discrete mathematics, we talked in terms of data integrity maintaining 1-1, and or onto properties. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PpSypVuzIcl"
      },
      "source": [
        "## Collaborators\n",
        "There were no collaborators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nrk-8EmgW4NP"
      },
      "source": [
        "# TODO What is True?\n",
        "Click on each warranted checkbox to toggle it to True (or back to False). \n",
        "\n",
        "NOTE: *This only works in Colab. If you run it in some other Jupyter notebook client/server environment you may have to change False to True (or vice versa) manually.*\n",
        "\n",
        "This self-assessment is subject to revision by a grader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGAjzgVRXR4M"
      },
      "source": [
        "#@markdown ## What is True about what I did?\n",
        "#@markdown ### I had fun.\n",
        "cb00 = True #@param {type:'boolean'}\n",
        "#@markdown ### I learned something new.\n",
        "cb01 = True #@param {type:'boolean'}\n",
        "#@markdown ### I achieved something meaningful, or something I can build upon at a later time.\n",
        "cb02 = True #@param {type:'boolean'}\n",
        "#@markdown ## What is True about my report?\n",
        "#@markdown ### I wrote a sufficient number of well-written sentences.\n",
        "cb03 = True #@param {type:'boolean'}\n",
        "#@markdown ### My report is free of mechanical infelicities.\n",
        "cb04 = True #@param {type:'boolean'}\n",
        "#@markdown ### I used Grammarly (or something better described in my report) to check for MIs.\n",
        "cb05 = True #@param {type:'boolean'}\n",
        "#@markdown ### I reported on any connections I found between these problems and something I already know. \n",
        "cb06 = True #@param {type:'boolean'}\n",
        "#@markdown ### I reported who were and what contribution each of my collaborators made.\n",
        "cb07 = True #@param {type:'boolean'}\n",
        "#@markdown ## What is True about my calculations?\n",
        "#@markdown ### I correctly calculated the number of times each gap size occurs. \n",
        "cb08 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the number of bits per gap size with a fixed encoding.\n",
        "cb09 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the total number of bits encoded with the Huffman encoding.\n",
        "cb10 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the total number of bits encoded with the fixed encoding.\n",
        "cb11 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the compression ratio from this fixed encoding.\n",
        "cb12 = False #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the size of the first ten million primes encoded as 32-bit integer binary data.\n",
        "cb13 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the compression ratio from the binary size.\n",
        "cb14 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the size of the first ten million primes encoded as ASCII data.\n",
        "cb15 = True #@param {type:'boolean'}\n",
        "#@markdown ### I correctly calculated the compression ratio from the ASCII size (just the primes, nothing else).\n",
        "cb16 = False #@param {type:'boolean'}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}